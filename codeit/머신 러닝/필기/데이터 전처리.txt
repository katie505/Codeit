Feature Scaling : Normalization
(데이터 전처리)
- 주어진 데이터를 그대로 사용하지 않고, 조금 가공해서 머신 러닝 모델을 학습시키기 더 좋은 형식으로 만들어 주는 것
- 머신 러닝 모델에 사용할 입력 변수들의 크기를 조정해서 일정 범위 내에 떨어지도록 바꿔주는 것
- feature scaling을 하면 경사 하강법을 조금 더 빨리할 수 있음
- 숫자의 크기를 0과 1사이로 만듦

1) Min-Max Normalization
- 데이터의 최솟값, 최댓값을 이용해서 데이터의 크기를 0과 1사이로 바꾸는 방법
- x(new) = x(old) - x(min) / x(max) - x(min)

Feature Scaling과 경사 하강법
- 만약 입력 변수의 단위가 천만일 경우 세타의 값이 조금만 바뀌어도 가설 함수의 아웃풋은 엄청난 차이가 남
-> 반면 절편은 항상 1과 곱해지기 때문에 값이 어느 정도 바뀌어도 아웃풋이 크게 변하지 않음
-> 아웃풋에 큰 영향을 준다는 것은 결국 평균 제곱 오차, 혹은 손실 함수에도 큰 영향을 준다는 뜻
=> 데이터 전처리를 해주면 세타와 절편에 비슷한 숫자들이 곱해지기 때문에 손실 함수에 비슷한 영향을 주게 됨
- 전처리를 하기 전 그래프를 보면 특정 지점에서 경사가 가장 가파른 방향, 즉 동고선과 수직이 되는 방향으로 조금씩 내려감
-> 경사 하강을 하면 지그재그 모양으로 그래프를 내려오게 됨
-> 많은 지점에서 경사가 가장 가파른 방향은 최소점을 향하는 방향이 아니기 때문
- 전처리 후 그래프는 동그란 그래프로 어떤 지점이든 경사가 가장 가파른 방향이 최소점을 향하는 방향이기 때문에 가장 가파른 경사를 따라서 내려오면 반듯하게 내려올 수 있음
=> 즉, 전처리를 해줌으로써 훨씬 더 빨리 최소점을 찾을 수 있는 것

2) Standardization
- x(new) = x(old) - 평균 / 표준 편차
- 표준화를 하면 항상 새로운 데이터의 평균은 0, 표준 편차는 1

One-hot Encoding
- 많은 머신 러닝 알고리즘은 인풋 데이터의 값이 수치형 데이터여야 함
-> 범주형 데이터일 때는 수치형 데이터로 바꿔줘야함
- 이 때 사용하는 것이 'One-hot encoding'
- 각 카테고리를 하나의 새로운 열로 만들어 주는 방법
EX) 혈액형이라는 열에는 네 개의 카테고리가 있으니까 이걸 4개의 열로 만들어 주는 방법
	-> 해당 혈액형의 값은 0, 나머지는 1로 채워줌
- One-hot Encoding을 하면 범주형 데이터에게 크고 작음의 엉뚱한 관계가 생기는 걸 방지하면서도 수치형 데이터로 바꿔 줄 수 있음
