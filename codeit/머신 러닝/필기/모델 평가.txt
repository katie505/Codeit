 <k겹 교차 검증(k-fold cross validation)>
- 머신 러닝 모델의 성능을 조금 더 정확하게 평가할 수 있는 방법
- 모델의 성능을 파악할 때 운 좋게 test set에서만 성능이 좋은 걸 수도 있고, test set에서만 성능이 안 좋게 나올 수도 있음
=> 이런 문제를 해결해 주는 방법 = 교차 검증
- 전체 데이터를 k개로 나누고 1개는 train set, k-1개는 test set으로 사용하여 모델 학습, 성능 파악 => 이를 k번 반복
- 모델의 성능을 여러 번 다른 데이터로 검증하기 때문에 평가에 대한 신뢰도가 올라감

k 고르기
- 가장 일반적으로 사용하는 숫자는 5
- 데이터가 많을수록 우연히 train set에서만 성능이 다르게 나올 확률이 적기 때문에 작은 k를 사용해도 됨

<Grid Search>
하이퍼 파라미터
- 머신 러닝 모델을 학습시키기 전에 사람이 미리 정해줘야 되는 변수들
- scikit - learn에서는 보통 모델을 만들 때 옵셔널 파라미터로 정해주는 변수들
- 하이퍼 파라미터에 어떤 값을 넣느냐에 따라 모델의 성능에 큰 차이가 있을 수 있기 때문에 모델의 성능을 최대한 높여주는 하이퍼 파라미터를 고르는 게 굉장히 중요
EX) Lasso 회귀에는 alpha, max_iter

Grid Search
- 좋은 하이퍼 파라미터를 고르는  방법 중 하나
- 굉장히 직관적
1) 정해줘야 하는 각 하이퍼 파라미터에 넣어보고 싶은 후보 값을 몇 개씩 정함
2) 모든 후보 값의 조합으로 모델을 학습시켰을 때 성능이 가장 좋았던 하이퍼 파라미터 조합 고르기
