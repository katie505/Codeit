<랜덤 포레스트>

*결정 트리는 이상적인 머신 러닝 모델이 되기 힘든 한 가지 특징을 갖는다. 바로 부정확성이다
= 다른 모델들에 비해서 성능이 안 좋다
=> 결정트리를 배우는 이유 : 결정 트리를 응용하면 성능이 좋은 다른 모델들을 만들 수 있음


앙상블(Ensemble)
- 결정 트리를 응용하는 가장 대표적인 방법
- 여러 독립적인 객체들이 만들어내는 조화로운 단체
- 하나의 모델을 쓰는 대신, 수많은 모델들을 사용해 종합적인 판단을 하는 것
- 수많은 모델들을 만들고 이 모델들의 예측을 합쳐서 종합적인 예측을 하는 기법

랜덤 포레스트
- 트리 앙상블 알고리즘
- 수많은 트리들을 임의로 만들고, 이 모델들의 결과를 다수결 투표로 종합해서 예측하는 모델

1) Bootstrapping
- 원래의 데이터 셋에서 임의로 새로운 데이터 셋을 만들어내는 방법
- 이렇게 만들어낸 데이터 셋을 bootstrap 데이터 셋이라고 부름
- 모델들을 다 정확히 똑같은 데이터 셋으로 학습시키면 다양하게 결과가 나오는 대신 모든 모델들이 비슷한 결과를 낼 수 있는데, 이걸 방지하기 위한 한 가지 방법이 bootstrap 데이터셋 사용하는 것

2) Bagging
- 모든 앙상블 기법을 사용하는 알고리즘들이 bootstrapping을 쓰는 것은 아님
- bootstrap 데이터 셋을 만들어내고, 모델들의 결정을 종합해서 (영어로는 aggregate) 예측을 하는 앙상블 기법을 bootstrap aggregating, 줄여서 bagging

3) 임의로 결정 트리 만들기
- 결정 트리를 그냥 만들 때는 각 속성들을 사용한 질문들의 지니 불순도를 구하고, 가장 낮은 애를 골라서 사용했지만 랜덤 포레스트를 만들 때는 속성 중에서 여러 개를 임의로 선택
- bootstraping을 사용해서 임의로 데이터 셋을 만들기 -> 결정 트리를 만들 때도 질문 노드들을 어느 정도는 임의로 만들기 
=> 이 두 단계를 엄청 많이 반복. 이런 식으로 bootstrap 데이터를 써서 엄청 많은 트리들을 임의로 만들기 = 랜덤 포레스트
