<결정 트리>
- 예/아니오로 답할 수 있는 어떤 질문들이 있고, 그 질문들의 답을 따라가면서 데이터를 분류하는 알고리즘
- 목적 : 학습 데이터를 직접 분류해보면서, 데이터들을 가장 잘 분류할 수 있는 노드들을 찾아내는 것
- 한 속성을 딱 한 번만 사용해야 되는 건 아님 
EX) 한 번은 주행 속도가 100을 넘었는지 질문하고 밑에 내려가서는 60을 넘었는지 질문
1) 하나의 시작 지점에서 퍼져나가는 모습이 마치 나무와 비슷
2) 한 단계 내려갈 때마다 왼쪽으로 갈지 오른쪽으로 갈지 선택
- leaf 노드는 항상 특정 예측값을 갖고 있음
- 나머지 노드들은 예/아니오로 답할 수 있는 질문

지니 불순도
- 어떻게 분류하거나 질문을 하는 게 좋고, 안 좋은지에 대한 기준, 손실 함수 같은 개념
- 데이터 셋이 정확히 얼마나 불순한지를 숫자로 표현
- 낮을수록 순수한 데이터 = 데이터 셋 안에 있는 데이터들이 하나의 분류에 집중돼있다는 것
- 높을수록 데이터가 불순한 것, 즉 데이터 셋에 다양한 분류가 섞여있다는 것

분류 노드 평가하기
- 좋은 분류 노드는 최대한 많은 데이터를 맞게 분류해야 됨 = 모든 데이터를 하나의 분류로 예측을 했을 때, 최대한 많이 맞아야 된다는 것
- 분류 노드를 만들 때는 항상 데이터 셋에서 가장 많은 분류로 만듦
- 불순도가 낮은, 순수한 데이터 셋이어야 함

질문 노드 평가하기
- 좋은 질문 = 데이터를 잘 나누는 질문
- 나뉜 데이터 셋들이 순수할수록, 또는 지니 불순도가 낮을수록 좋은 질문
- 질문 노드의 성능을 판단할 때는 나뉜 데이터 셋의 '지니 불순도' 사용
- 질문으로 나눠진 데이터 셋들의 평균 지니 불순도 = 각각의 (데이터 셋의 지니 불순도 * 데이터 수)의 합 / 총 데이터의 수

노드 고르기(여러 개의 분류, 또는 질문 노드들에서 가장 좋은 노드 고르기)
- 모든 질문들의 불순도를 계산하여 불순도가 가장 낮은 노드 뽑기
- 분류 노드의 불순도가 가장 작다 = 이미 데이터가 잘 나눠져 있기 때문에 있는 그대로 분류해도 됨
=> 질문을 통해서 지금 잇는 데이터 셋보다 불순도를 더 낮출 수 있다는 말

모든 노드 만들기
- root 노드의 왼쪽부터 다시 학습 데이터를 가지고 가장 좋은 노드를 찾으면 됨
- 후보 질문들을 이용해서 나눴을 때의 불순도를 계산하여 지니 불순도가 가장 낮은 질문을 노드로 만듦
- 결정 트리 깊이는 미리 정할 수도 있다 = 특정 깊이까지 내려오면 더 이상 불순도를 비교하는 게 아니라 멈추고 분류 노드로 만들면 됨
=> 원하는 깊이까지는 가장 지니 불순도가 낮은 즉, 학습 데이터들을 가장 순수하게 나눠주는 질문, 또는 분류 노드를 고르면서 결정 트리를 만들어 나감

속성이 숫자형일 때 질문 노드
EX) 체온이 몇 도인지 나타내는 데이터
1) 가장 먼저 체온 데이터 정렬
2) 각 연속된 2개의 체온 데이터의 평균 계산 => 평균들을 이용해서 질문들을 하나씩 만들기
3) 모든 평균 체온에 대해서 지니 불순도 계산하기 => 평균을 기준으로 삼았을 때 데이터가 얼마나 잘 분류됐는지를 전부 계산
4) 가장 지니 불순도가 낮은 질문 사용하면 됨

속성 중요도(feature importance)
1) 노드 중요도(Node Importance)
- 속성 중요도를 계산하기 위해서는 먼저 각 노드 하나하나의 중요도를 계산해야함
- 노드 중요도 = ni
- n : 중요도를 계산하려는 노드까지 오는 학습 데이터의 수
- GI : 노드까지 오는 데이터 셋의 불순도
- m : 전체 학습 데이터의 수
- 계산하려는 노드까지 오는 학습 데이터 수랑 불순도를 곱한 후, 총 데이터 수로 나눠주기
-> 이걸 중요도를 계산하려는 노드, 왼쪽 자식 노드, 오른쪽 자식 노드에서 다 계산
-> 그리고 현재 노드의 계산 값에서 나머지 두 노드의 계산 값 빼기
- ni = n/m*GI - n(left)/m*GI(left) - n(right)/m*GI(right)
= 한 노드에서 데이터를 두 개로 나눴을 때, 데이터 수에 비례해서 불순도가 얼마나 줄어들었는지 계산하는 것
- 불순도가 낮아질수록 나눠지는 데이터 셋들이 점점 한 종류의 데이터가 많아짐 = 나눠지는 데이터 셋들에 대해서 점점 더 알아간다 또는 '더 많은 정보를 얻는다'라고 해서 
=> 노드 중요도를 '정보 증가량(information gain)이라고도 부름

2) 속성 중요도(Feature Importance) = 평균 지니 감수
- 모든 질문 노드의 중요도를 이용해서 특정 속성이 얼마나 중요한지 계산할 수 있음
- 해당 속성이 얼마나 중요한지 알고 싶다면 해당 속성을 갖는 모든 노드의 중요도의 합 / 모든 노드 중요도 합
= 모든 노드가 데이터를 양 갈래로 나누면서 나누는 데이터 셋들의 지니 불순도를 낮추는데 전체적으로 낮춰진 불순도에서 특정 속성 하나가 낮춘 불순도가 얼마나 되는지 계산
=> 최종적으로 구한 값 = 속성의 평균 지니 감소
- 각 속성의 평균 지니 감소를 이용하면, 특정 속성이 결정 트리 안에서 평균적으로 얼마나 불순도를 낮췄는지를 계산할 수 있고, 결정 트리 안에서 그 속성이 얼마나 중요한지 판단할 수 있음
